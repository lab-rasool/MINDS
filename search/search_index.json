{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the MINDS Database Documentation .container { display: flex; align-items: center; /* Aligns items vertically in the center */ } .text { margin-left: 20px; /* Adjusts spacing between the logo and the text */ font-size: 40px; /* Adjust the font size as needed */ font-weight: bold; /* Makes the text bold */ /* Add more styling as needed */ } M ultimodal I ntegration of O n cology D ata S ystem MINDS is a framework designed to integrate multimodal oncology data. It queries and integrates data from multiple sources, including clinical data, genomic data, and imaging data from the NIH NCI CRDC and TCIA portals. MINDS is a framework designed to integrate multimodal oncology data. It queries and integrates data from multiple sources, including clinical data, genomic data, and imaging data from the NIH NCI CRDC and TCIA portals. Installation Currently the cloud version of MINDS is in closed beta, but, you can still recreate the MINDS database locally. To get the local version of the MINDS database running, you will need to setup a MySQL database and populate it with the MINDS schema. This can be easily done using a docker container. First, you will need to install docker. You can find the installation instructions for your operating system here . Next, you will need to pull the MySQL docker image and run a container with the following command. NOTE: Please replace my-secret-pw with your desired password and port with the port you want to use to access the database. The default port for MySQL is 3306. The following command will not work until you replace port with a valid port number. docker run -d --name minds -e MYSQL_ROOT_PASSWORD=my-secret-pw -e MYSQL_DATABASE=minds -p port:3306 mysql Finally, to install the MINDS python package use the following pip command: pip install git+https://github.com/lab-rasool/MINDS.git After installing the package, please create a .env file in the root directory of the project with the following variables: HOST=localhost PORT=3306 DB_USER=root PASSWORD=my-secret-pw DATABASE=minds Usage Initial setup and automated updates If you have locally setup the MINDS database, then you will need to populate it with data. To do this, or to update the database with the latest data, you can use the following command: # Import the minds package import minds # Update the database with the latest data minds.update() Querying the MINDS database The MINDS python package provides a python interface to the MINDS database. You can use this interface to query the database and return the results as a pandas dataframe. import minds # get a list of all the tables in the database tables = minds.get_tables() # get a list of all the columns in a table columns = minds.get_columns(\"clinical\") # Query the database directly query = \"SELECT * FROM nihnci.clinical WHERE project_id = 'TCGA-LUAD' LIMIT 10\" df = minds.query(query) Building the cohort and downloading the data # Generate a cohort to download from query query_cohort = minds.build_cohort(query=query, output_dir=\"./data\") # or you can now directly supply a cohort from GDC gdc_cohort = minds.build_cohort(gdc_cohort=\"cohort_Unsaved_Cohort.2024-02-12.tsv\", output_dir=\"./data\") # to get the cohort details cohort.stats() # to download the data from the cohort to the output directory specified # you can also specify the number of threads to use and the modalities to exclude or include cohort.download(threads=12, exclude=[\"Slide Image\"]) Please cite our work Note : Currently under review at the Sensors journal special issue on \"Multimodal Data Fusion Technologies and Applications in Intelligent System\". Till then please cite our arXiv preprint: @misc{tripathi2023building, title={Building Flexible, Scalable, and Machine Learning-ready Multimodal Oncology Datasets}, author={Aakash Tripathi and Asim Waqas and Kavya Venkatesan and Yasin Yilmaz and Ghulam Rasool}, year={2023}, eprint={2310.01438}, archivePrefix={arXiv}, primaryClass={cs.LG} }","title":"Home"},{"location":"#welcome-to-the-minds-database-documentation","text":".container { display: flex; align-items: center; /* Aligns items vertically in the center */ } .text { margin-left: 20px; /* Adjusts spacing between the logo and the text */ font-size: 40px; /* Adjust the font size as needed */ font-weight: bold; /* Makes the text bold */ /* Add more styling as needed */ } M ultimodal I ntegration of O n cology D ata S ystem MINDS is a framework designed to integrate multimodal oncology data. It queries and integrates data from multiple sources, including clinical data, genomic data, and imaging data from the NIH NCI CRDC and TCIA portals. MINDS is a framework designed to integrate multimodal oncology data. It queries and integrates data from multiple sources, including clinical data, genomic data, and imaging data from the NIH NCI CRDC and TCIA portals.","title":"Welcome to the MINDS Database Documentation"},{"location":"#installation","text":"Currently the cloud version of MINDS is in closed beta, but, you can still recreate the MINDS database locally. To get the local version of the MINDS database running, you will need to setup a MySQL database and populate it with the MINDS schema. This can be easily done using a docker container. First, you will need to install docker. You can find the installation instructions for your operating system here . Next, you will need to pull the MySQL docker image and run a container with the following command. NOTE: Please replace my-secret-pw with your desired password and port with the port you want to use to access the database. The default port for MySQL is 3306. The following command will not work until you replace port with a valid port number. docker run -d --name minds -e MYSQL_ROOT_PASSWORD=my-secret-pw -e MYSQL_DATABASE=minds -p port:3306 mysql Finally, to install the MINDS python package use the following pip command: pip install git+https://github.com/lab-rasool/MINDS.git After installing the package, please create a .env file in the root directory of the project with the following variables: HOST=localhost PORT=3306 DB_USER=root PASSWORD=my-secret-pw DATABASE=minds","title":"Installation"},{"location":"#usage","text":"","title":"Usage"},{"location":"#initial-setup-and-automated-updates","text":"If you have locally setup the MINDS database, then you will need to populate it with data. To do this, or to update the database with the latest data, you can use the following command: # Import the minds package import minds # Update the database with the latest data minds.update()","title":"Initial setup and automated updates"},{"location":"#querying-the-minds-database","text":"The MINDS python package provides a python interface to the MINDS database. You can use this interface to query the database and return the results as a pandas dataframe. import minds # get a list of all the tables in the database tables = minds.get_tables() # get a list of all the columns in a table columns = minds.get_columns(\"clinical\") # Query the database directly query = \"SELECT * FROM nihnci.clinical WHERE project_id = 'TCGA-LUAD' LIMIT 10\" df = minds.query(query)","title":"Querying the MINDS database"},{"location":"#building-the-cohort-and-downloading-the-data","text":"# Generate a cohort to download from query query_cohort = minds.build_cohort(query=query, output_dir=\"./data\") # or you can now directly supply a cohort from GDC gdc_cohort = minds.build_cohort(gdc_cohort=\"cohort_Unsaved_Cohort.2024-02-12.tsv\", output_dir=\"./data\") # to get the cohort details cohort.stats() # to download the data from the cohort to the output directory specified # you can also specify the number of threads to use and the modalities to exclude or include cohort.download(threads=12, exclude=[\"Slide Image\"])","title":"Building the cohort and downloading the data"},{"location":"#please-cite-our-work","text":"Note : Currently under review at the Sensors journal special issue on \"Multimodal Data Fusion Technologies and Applications in Intelligent System\". Till then please cite our arXiv preprint: @misc{tripathi2023building, title={Building Flexible, Scalable, and Machine Learning-ready Multimodal Oncology Datasets}, author={Aakash Tripathi and Asim Waqas and Kavya Venkatesan and Yasin Yilmaz and Ghulam Rasool}, year={2023}, eprint={2310.01438}, archivePrefix={arXiv}, primaryClass={cs.LG} }","title":"Please cite our work"},{"location":"reference/","text":"Reference Cohort Source code in app\\minds\\__init__.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 class Cohort : def __init__ ( self , data , output_dir ): self . data = data self . output_dir = output_dir self . manifest_file = os . path . join ( output_dir , \"manifest.json\" ) def generate_manifest ( self ): aggregator = Aggregator ( self . data , self . output_dir ) aggregator . generate_manifest () def download ( self , threads : int = 4 , include : list = None , exclude : list = None ): if not os . path . exists ( self . manifest_file ): raise FileNotFoundError ( f \"No manifest file found in { self . output_dir } . Please run generate_manifest first.\" ) self . _download_gdc_files ( threads , include = include , exclude = exclude ) self . _download_tcia_files ( threads ) def include ( self , modalities ): print ( f \"Only including { modalities } modalities in download\" ) def stats ( self ): \"\"\"Prints the statistics of the cohort in terms of file count and total size Returns: dict: A dictionary containing the statistics of the cohort \"\"\" with open ( self . manifest_file , \"r\" ) as f : manifest = json . load ( f ) stats_dict = {} for entry in manifest : for key , value in entry . items (): if isinstance ( value , list ): patient_size = 0 for file in value : try : patient_size += file [ \"file_size\" ] except Exception as e : pass if key not in stats_dict : stats_dict [ key ] = { \"file_count\" : len ( value ), \"total_size\" : patient_size , } else : stats_dict [ key ][ \"file_count\" ] += len ( value ) stats_dict [ key ][ \"total_size\" ] += patient_size # Sort the dictionary by total size in descending order sorted_stats = sorted ( stats_dict . items (), key = lambda x : x [ 1 ][ \"total_size\" ], reverse = True ) console = Console () table = Table ( show_header = True , header_style = \"bold green\" ) table . add_column ( \"Modality\" ) table . add_column ( \"File Count\" ) table . add_column ( \"Total Size\" ) for key , value in sorted_stats : size = value [ \"total_size\" ] if size > 1024 * 1024 * 1024 : size = f \" { size / ( 1024 * 1024 * 1024 ) : .2f } GB\" elif size > 1024 * 1024 : size = f \" { size / ( 1024 * 1024 ) : .2f } MB\" else : size = f \" { size / 1024 : .2f } KB\" table . add_row ( key , str ( value [ \"file_count\" ]), size ) console . print ( table ) return dict ( sorted_stats ) def _download_gdc_files ( self , threads , include = None , exclude = None ): gdc_downloader = GDCFileDownloader ( self . output_dir , MAX_WORKERS = threads , include = include , exclude = exclude ) gdc_downloader . process_cases () def _download_tcia_files ( self , threads , include = None , exclude = None ): tcia_downloader = TCIAFileDownloader ( self . output_dir , MAX_WORKERS = threads , include = include , exclude = exclude ) tcia_downloader . process_cases () stats () Prints the statistics of the cohort in terms of file count and total size Returns: dict \u2013 A dictionary containing the statistics of the cohort Source code in app\\minds\\__init__.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def stats ( self ): \"\"\"Prints the statistics of the cohort in terms of file count and total size Returns: dict: A dictionary containing the statistics of the cohort \"\"\" with open ( self . manifest_file , \"r\" ) as f : manifest = json . load ( f ) stats_dict = {} for entry in manifest : for key , value in entry . items (): if isinstance ( value , list ): patient_size = 0 for file in value : try : patient_size += file [ \"file_size\" ] except Exception as e : pass if key not in stats_dict : stats_dict [ key ] = { \"file_count\" : len ( value ), \"total_size\" : patient_size , } else : stats_dict [ key ][ \"file_count\" ] += len ( value ) stats_dict [ key ][ \"total_size\" ] += patient_size # Sort the dictionary by total size in descending order sorted_stats = sorted ( stats_dict . items (), key = lambda x : x [ 1 ][ \"total_size\" ], reverse = True ) console = Console () table = Table ( show_header = True , header_style = \"bold green\" ) table . add_column ( \"Modality\" ) table . add_column ( \"File Count\" ) table . add_column ( \"Total Size\" ) for key , value in sorted_stats : size = value [ \"total_size\" ] if size > 1024 * 1024 * 1024 : size = f \" { size / ( 1024 * 1024 * 1024 ) : .2f } GB\" elif size > 1024 * 1024 : size = f \" { size / ( 1024 * 1024 ) : .2f } MB\" else : size = f \" { size / 1024 : .2f } KB\" table . add_row ( key , str ( value [ \"file_count\" ]), size ) console . print ( table ) return dict ( sorted_stats ) build_cohort ( output_dir , query = None , gdc_cohort = None , manifest = None ) Builds a cohort based on a query or a GDC cohort file and returns a Cohort object. Source code in app\\minds\\__init__.py 149 150 151 152 153 154 155 156 157 158 159 160 161 def build_cohort ( output_dir , query = None , gdc_cohort = None , manifest = None ): \"\"\"Builds a cohort based on a query or a GDC cohort file and returns a Cohort object.\"\"\" if query : cohort_data = db . get_minds_cohort ( query ) elif gdc_cohort : cohort_data = db . get_gdc_cohort ( gdc_cohort ) else : raise ValueError ( \"Either a query or a gdc_cohort file must be provided\" ) cohort = Cohort ( cohort_data , output_dir ) if manifest is None : cohort . generate_manifest () return cohort get_columns ( table ) Get the list of columns in a table Parameters table : str The name of the table Returns list A list of columns in the table Source code in app\\minds\\__init__.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def get_columns ( table ): \"\"\"Get the list of columns in a table Parameters ---------- table : str The name of the table Returns ------- list A list of columns in the table \"\"\" return db . get_columns ( table ) get_tables () Get the list of tables in the database Returns list A list of tables in the database Source code in app\\minds\\__init__.py 18 19 20 21 22 23 24 25 26 def get_tables (): \"\"\"Get the list of tables in the database Returns ------- list A list of tables in the database \"\"\" return db . get_tables () query ( query ) Query the database and return the result as a pandas dataframe Parameters query_string : str The query string to be executed on the database Returns pandas.DataFrame The result of the query Source code in app\\minds\\__init__.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def query ( query ): \"\"\"Query the database and return the result as a pandas dataframe Parameters ---------- query_string : str The query string to be executed on the database Returns ------- pandas.DataFrame The result of the query \"\"\" return db . execute ( query )","title":"Reference"},{"location":"reference/#reference","text":"","title":"Reference"},{"location":"reference/#app.minds.Cohort","text":"Source code in app\\minds\\__init__.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 class Cohort : def __init__ ( self , data , output_dir ): self . data = data self . output_dir = output_dir self . manifest_file = os . path . join ( output_dir , \"manifest.json\" ) def generate_manifest ( self ): aggregator = Aggregator ( self . data , self . output_dir ) aggregator . generate_manifest () def download ( self , threads : int = 4 , include : list = None , exclude : list = None ): if not os . path . exists ( self . manifest_file ): raise FileNotFoundError ( f \"No manifest file found in { self . output_dir } . Please run generate_manifest first.\" ) self . _download_gdc_files ( threads , include = include , exclude = exclude ) self . _download_tcia_files ( threads ) def include ( self , modalities ): print ( f \"Only including { modalities } modalities in download\" ) def stats ( self ): \"\"\"Prints the statistics of the cohort in terms of file count and total size Returns: dict: A dictionary containing the statistics of the cohort \"\"\" with open ( self . manifest_file , \"r\" ) as f : manifest = json . load ( f ) stats_dict = {} for entry in manifest : for key , value in entry . items (): if isinstance ( value , list ): patient_size = 0 for file in value : try : patient_size += file [ \"file_size\" ] except Exception as e : pass if key not in stats_dict : stats_dict [ key ] = { \"file_count\" : len ( value ), \"total_size\" : patient_size , } else : stats_dict [ key ][ \"file_count\" ] += len ( value ) stats_dict [ key ][ \"total_size\" ] += patient_size # Sort the dictionary by total size in descending order sorted_stats = sorted ( stats_dict . items (), key = lambda x : x [ 1 ][ \"total_size\" ], reverse = True ) console = Console () table = Table ( show_header = True , header_style = \"bold green\" ) table . add_column ( \"Modality\" ) table . add_column ( \"File Count\" ) table . add_column ( \"Total Size\" ) for key , value in sorted_stats : size = value [ \"total_size\" ] if size > 1024 * 1024 * 1024 : size = f \" { size / ( 1024 * 1024 * 1024 ) : .2f } GB\" elif size > 1024 * 1024 : size = f \" { size / ( 1024 * 1024 ) : .2f } MB\" else : size = f \" { size / 1024 : .2f } KB\" table . add_row ( key , str ( value [ \"file_count\" ]), size ) console . print ( table ) return dict ( sorted_stats ) def _download_gdc_files ( self , threads , include = None , exclude = None ): gdc_downloader = GDCFileDownloader ( self . output_dir , MAX_WORKERS = threads , include = include , exclude = exclude ) gdc_downloader . process_cases () def _download_tcia_files ( self , threads , include = None , exclude = None ): tcia_downloader = TCIAFileDownloader ( self . output_dir , MAX_WORKERS = threads , include = include , exclude = exclude ) tcia_downloader . process_cases ()","title":"Cohort"},{"location":"reference/#app.minds.Cohort.stats","text":"Prints the statistics of the cohort in terms of file count and total size Returns: dict \u2013 A dictionary containing the statistics of the cohort Source code in app\\minds\\__init__.py 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def stats ( self ): \"\"\"Prints the statistics of the cohort in terms of file count and total size Returns: dict: A dictionary containing the statistics of the cohort \"\"\" with open ( self . manifest_file , \"r\" ) as f : manifest = json . load ( f ) stats_dict = {} for entry in manifest : for key , value in entry . items (): if isinstance ( value , list ): patient_size = 0 for file in value : try : patient_size += file [ \"file_size\" ] except Exception as e : pass if key not in stats_dict : stats_dict [ key ] = { \"file_count\" : len ( value ), \"total_size\" : patient_size , } else : stats_dict [ key ][ \"file_count\" ] += len ( value ) stats_dict [ key ][ \"total_size\" ] += patient_size # Sort the dictionary by total size in descending order sorted_stats = sorted ( stats_dict . items (), key = lambda x : x [ 1 ][ \"total_size\" ], reverse = True ) console = Console () table = Table ( show_header = True , header_style = \"bold green\" ) table . add_column ( \"Modality\" ) table . add_column ( \"File Count\" ) table . add_column ( \"Total Size\" ) for key , value in sorted_stats : size = value [ \"total_size\" ] if size > 1024 * 1024 * 1024 : size = f \" { size / ( 1024 * 1024 * 1024 ) : .2f } GB\" elif size > 1024 * 1024 : size = f \" { size / ( 1024 * 1024 ) : .2f } MB\" else : size = f \" { size / 1024 : .2f } KB\" table . add_row ( key , str ( value [ \"file_count\" ]), size ) console . print ( table ) return dict ( sorted_stats )","title":"stats"},{"location":"reference/#app.minds.build_cohort","text":"Builds a cohort based on a query or a GDC cohort file and returns a Cohort object. Source code in app\\minds\\__init__.py 149 150 151 152 153 154 155 156 157 158 159 160 161 def build_cohort ( output_dir , query = None , gdc_cohort = None , manifest = None ): \"\"\"Builds a cohort based on a query or a GDC cohort file and returns a Cohort object.\"\"\" if query : cohort_data = db . get_minds_cohort ( query ) elif gdc_cohort : cohort_data = db . get_gdc_cohort ( gdc_cohort ) else : raise ValueError ( \"Either a query or a gdc_cohort file must be provided\" ) cohort = Cohort ( cohort_data , output_dir ) if manifest is None : cohort . generate_manifest () return cohort","title":"build_cohort"},{"location":"reference/#app.minds.get_columns","text":"Get the list of columns in a table","title":"get_columns"},{"location":"reference/#app.minds.get_columns--parameters","text":"table : str The name of the table","title":"Parameters"},{"location":"reference/#app.minds.get_columns--returns","text":"list A list of columns in the table Source code in app\\minds\\__init__.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def get_columns ( table ): \"\"\"Get the list of columns in a table Parameters ---------- table : str The name of the table Returns ------- list A list of columns in the table \"\"\" return db . get_columns ( table )","title":"Returns"},{"location":"reference/#app.minds.get_tables","text":"Get the list of tables in the database","title":"get_tables"},{"location":"reference/#app.minds.get_tables--returns","text":"list A list of tables in the database Source code in app\\minds\\__init__.py 18 19 20 21 22 23 24 25 26 def get_tables (): \"\"\"Get the list of tables in the database Returns ------- list A list of tables in the database \"\"\" return db . get_tables ()","title":"Returns"},{"location":"reference/#app.minds.query","text":"Query the database and return the result as a pandas dataframe","title":"query"},{"location":"reference/#app.minds.query--parameters","text":"query_string : str The query string to be executed on the database","title":"Parameters"},{"location":"reference/#app.minds.query--returns","text":"pandas.DataFrame The result of the query Source code in app\\minds\\__init__.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 def query ( query ): \"\"\"Query the database and return the result as a pandas dataframe Parameters ---------- query_string : str The query string to be executed on the database Returns ------- pandas.DataFrame The result of the query \"\"\" return db . execute ( query )","title":"Returns"}]}